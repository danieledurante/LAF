# LAF: Locally Adaptive Factor (LAF) processes for multivariate time series

This repository is associated with the paper Durante, Scarpa and Dunson (2014). [*Locally Adaptive Factor Processes for Multivariate Time Series*](http://jmlr.org/papers/v15/durante14a.html). Journal of Machine Learning Research, 15:1493—1522, and aims at providing **code and materials to implement the Gibbs sampler algorithm for the mean-covariance regression model described in the paper**. Readers interested in this topic can also refer to the NIPS paper Durante, Scarpa and Dunson (2013). [*Locally Adaptive Bayesian Multivariate Time Series*](http://papers.nips.cc/paper/5115-locally-adaptive-bayesian-multivariate-time-series), Advances in Neural Information Processing Systems, 26:1664—1672.

Here we provide the `Julia` implementation from [jmxpearson](https://github.com/jmxpearson), with additional comments and guidelines. For a version of the Gibbs sample code in `Python` refer to the [original repository](https://github.com/jmxpearson/laf) from [jmxpearson](https://github.com/jmxpearson). Note that, for the `Julia` implementation, the following **dependencies**:

    - Julia 0.4+ (dev branch as of this testing)
    - PyPlot (for plotting)
    - Distributions

are required. 

The materials for the implementation can be found in the directory [julia](https://github.com/danieledurante/LAF/tree/master/julia), which provides the following files:

- **Modules to implement relevant routines required for the Gibbs sampler**

    - `SStools.jl`: Contains implementations of the Kalman filter and smoother, as well as functions to draw samples from the simulation smoother algorithm of [Durbin and Koopman](http://biomet.oxfordjournals.org/content/89/3/603.short).
    - `NGPtools.jl`: Contains an implementation of the nested Gaussian process of [Zhu and Dunson](http://amstat.tandfonline.com/doi/abs/10.1080/01621459.2013.838568#.VdsWUNNViko)

- **Codes to generate data where to test the different routines and the final Gibbs sampler**

    - `test_signals.ipynb` generates test data with locally-varying smoothness after the examples in [Donoho and Johnstone](http://biomet.oxfordjournals.org/content/81/3/425.short). This code is in Python.
    - `make_labcr_test_data.ipynb` generates data from a time-varying factor process for testing LABCR and saves the results in a jld (HDF5) file.

- **Codes to validate the different routines**

    - Kalman Filter and Simulation Smoother
        - `kalman_integration_test.ipynb` contains tests of the Kalman filter and smoother code.
        - `kalman_interleaved_integration_tests.ipynb` contains tests of "univariate" Kalman filter/smoother algorithms that collapse vector-valued observations into a single univariate time series. This can result in large speedups when the covariance matrix of the observation model is diagonal.
    - Nested Gaussian Process (nGP)
        - `integration_test_nGP_samples.ipynb` tests the ability of the code to draw samples from a (2, 1) nested Gaussian process.
        - `MCMC_integration_test.ipynb` is an integration test for inference using the nested Gaussian process. It makes use of the data generated by `test_signals`.

- **Final code for the LAF Gibbs sampler and validation on a tutorial simulation**

    - `make_labcr_test_data.ipynb` generates data from a time-varying factor process for testing LABCR and saves the results in a jld (HDF5) file.

